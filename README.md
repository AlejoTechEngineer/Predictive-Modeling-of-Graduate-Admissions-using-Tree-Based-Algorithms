<div align="center">

# ğŸ“ Predictive Modeling of Graduate Admissions using Tree-Based Algorithms

</div>

<div align="center">

![Python](https://img.shields.io/badge/Python-3.14.3-blue?style=for-the-badge&logo=python&logoColor=white)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.8.0-orange?style=for-the-badge&logo=scikit-learn&logoColor=white)
![pandas](https://img.shields.io/badge/pandas-3.0.1-150458?style=for-the-badge&logo=pandas&logoColor=white)
![matplotlib](https://img.shields.io/badge/matplotlib-3.10.8-11557c?style=for-the-badge)
![Status](https://img.shields.io/badge/Status-Completed-success?style=for-the-badge)
![University](https://img.shields.io/badge/UNIR-IngenierÃ­a%20InformÃ¡tica-red?style=for-the-badge)

**Aprendizaje AutomÃ¡tico y MinerÃ­a de Datos**  
**FundaciÃ³n Universitaria Internacional de La Rioja â€” 2026**

*ClasificaciÃ³n supervisada de candidatos a posgrado mediante Decision Tree y Random Forest*

</div>

---

## ğŸ“‹ Tabla de Contenido

- [DescripciÃ³n del Proyecto](#-descripciÃ³n-del-proyecto)
- [Dataset](#-dataset)
- [Estructura del Repositorio](#-estructura-del-repositorio)
- [Pipeline del AnÃ¡lisis](#-pipeline-del-anÃ¡lisis)
- [Modelos Implementados](#-modelos-implementados)
- [Resultados](#-resultados)
- [GrÃ¡ficos Generados](#-grÃ¡ficos-generados)
- [InstalaciÃ³n y EjecuciÃ³n](#-instalaciÃ³n-y-ejecuciÃ³n)
- [Conclusiones](#-conclusiones)
- [TecnologÃ­as](#-tecnologÃ­as)
- [Autor](#-autor)

---

## ğŸš€ DescripciÃ³n del Proyecto

Este proyecto aplica tÃ©cnicas de **clasificaciÃ³n supervisada** sobre el dataset *Graduate Admissions* para predecir si un candidato tiene alta probabilidad de ser admitido en un programa de posgrado.

La variable continua `Chance of Admit` se transforma en una **variable binaria**:

```
Admit = "yes"  â†’  si Chance of Admit â‰¥ 0.6
Admit = "no"   â†’  si Chance of Admit < 0.6
```

Se implementan y comparan dos algoritmos basados en Ã¡rboles:
- ğŸŒ³ **Decision Tree Classifier**
- ğŸŒ² **Random Forest Classifier**

El anÃ¡lisis sigue un pipeline completo: exploraciÃ³n â†’ preprocesamiento â†’ modelado â†’ evaluaciÃ³n â†’ interpretaciÃ³n.

---

## ğŸ“Š Dataset

| Atributo | Detalle |
|---|---|
| **Fuente** | [Kaggle - Graduate Admissions](https://www.kaggle.com/mohansacharya/graduate-admissions) |
| **Registros** | 500 candidatos |
| **Variables** | 9 (8 predictoras + 1 objetivo) |
| **Missing values** | âœ… Ninguno |
| **Tipo de problema** | ClasificaciÃ³n binaria supervisada |

### Variables del Dataset

| Variable | Tipo | DescripciÃ³n |
|---|---|---|
| `GRE Score` | int | Puntaje GRE (290â€“340) |
| `TOEFL Score` | int | Puntaje TOEFL (92â€“120) |
| `University Rating` | int | CalificaciÃ³n de la universidad (1â€“5) |
| `SOP` | float | Calidad del Statement of Purpose (1â€“5) |
| `LOR` | float | Calidad de la carta de recomendaciÃ³n (1â€“5) |
| `CGPA` | float | Promedio acadÃ©mico acumulado (6.8â€“9.92) |
| `Research` | int | Experiencia investigativa (0 o 1) |
| `Chance of Admit` | float | Probabilidad de admisiÃ³n (0.34â€“0.97) â†’ **variable objetivo** |

### DistribuciÃ³n de Clases

```
yes (â‰¥ 0.6)  â†’  405 registros  â†’  81%
no  (< 0.6)  â†’   95 registros  â†’  19%
```

> âš ï¸ Desbalance moderado. No crÃ­tico, pero influye en mÃ©tricas por clase.

---

## ğŸ“ Estructura del Repositorio

```
ğŸ“¦ Predictive-Modeling-of-Graduate-Admissions-using-Tree-Based-Algorithms
â”œâ”€â”€ ğŸ“„ admission_clasificacion.py                      # Script principal â€” pipeline completo
â”œâ”€â”€ ğŸ“Š Admission_Predict_Ver1.1.csv                    # Dataset principal (500 registros)
â”œâ”€â”€ ğŸ“Š Admission_Predict.csv                           # Dataset versiÃ³n anterior (400 registros)
â”œâ”€â”€ ğŸ“„ Desarrollo_Proyecto_Alejandro_De_Mendoza.pdf    # Informe tÃ©cnico completo
â”œâ”€â”€ ğŸ–¼ï¸ 01_analisis_exploratorio.png                    # EDA: distribuciones y scatter plots
â”œâ”€â”€ ğŸ–¼ï¸ 02_correlacion.png                              # Matriz de correlaciÃ³n de Pearson
â”œâ”€â”€ ğŸ–¼ï¸ 03_arbol_decision.png                           # VisualizaciÃ³n del Ã¡rbol entrenado
â”œâ”€â”€ ğŸ–¼ï¸ 04_importancia_dt.png                           # Feature importance â€” Decision Tree
â”œâ”€â”€ ğŸ–¼ï¸ 05_importancia_rf.png                           # Feature importance â€” Random Forest
â”œâ”€â”€ ğŸ–¼ï¸ 06_matrices_confusion.png                       # Matrices de confusiÃ³n comparadas
â”œâ”€â”€ ğŸ–¼ï¸ 07_curva_roc.png                                # Curva ROC â€” comparaciÃ³n de modelos
â””â”€â”€ ğŸ“„ README.md                                       # Este archivo
```

---

## ğŸ”„ Pipeline del AnÃ¡lisis

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PIPELINE COMPLETO                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. CARGA   â”‚  2. EDA      â”‚  3. PREPRO   â”‚  4. MODELADO        â”‚
â”‚             â”‚              â”‚              â”‚                     â”‚
â”‚  CSV â†’      â”‚  EstadÃ­s-    â”‚  Binarizar   â”‚  Decision Tree      â”‚
â”‚  DataFrame  â”‚  ticas desc. â”‚  variable    â”‚  Random Forest      â”‚
â”‚  Strip cols â”‚  CorrelaciÃ³n â”‚  Encode y    â”‚  Train 70%          â”‚
â”‚  Shape      â”‚  Scatter     â”‚  split 70/30 â”‚  Test  30%          â”‚
â”‚  isnull     â”‚  Histogramas â”‚  Stratify    â”‚  Stratified         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     5. EVALUACIÃ“N                               â”‚
â”‚  Accuracy â”‚ AUC-ROC â”‚ Conf. Matrix â”‚ Class. Report â”‚ CV 5-fold  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¤– Modelos Implementados

### ğŸŒ³ Decision Tree Classifier

```python
DecisionTreeClassifier(
    criterion='gini',       # Ãndice de Gini como medida de impureza
    max_depth=4,            # Profundidad mÃ¡xima â†’ evita sobreajuste
    min_samples_leaf=10,    # MÃ­nimo 10 muestras por hoja
    random_state=42         # Reproducibilidad garantizada
)
```

**Regla principal aprendida por el modelo:**
```
|--- CGPA <= 7.91  â†’  class: NO  (baja prob. de admisiÃ³n)
|--- CGPA >  7.91  â†’  continÃºa evaluando GRE, TOEFL, SOP...
```

### ğŸŒ² Random Forest Classifier

```python
RandomForestClassifier(
    n_estimators=100,       # 100 Ã¡rboles en el ensemble
    max_depth=5,            # Profundidad por Ã¡rbol
    min_samples_leaf=5,     # RegularizaciÃ³n por hoja
    random_state=42         # Reproducibilidad
)
```

**PredicciÃ³n final:**
```
P(Admit=yes) = (1/100) Ã— Î£ Pb(yes)   â†’  votaciÃ³n mayoritaria
```

---

## ğŸ“ˆ Resultados

### Tabla Comparativa

| MÃ©trica | ğŸŒ³ Decision Tree | ğŸŒ² Random Forest | Mejor |
|---|---|---|---|
| **Accuracy** | 89.33% | **91.33%** | ğŸŒ² RF |
| **AUC-ROC** | 0.8879 | **0.9054** | ğŸŒ² RF |
| **CV Accuracy (5-fold)** | 0.8960 Â± 0.0403 | **0.9080 Â± 0.0312** | ğŸŒ² RF |
| **Precision (yes)** | 0.93 | 0.92 | ğŸŒ³ DT |
| **Recall (yes)** | 0.93 | **0.98** | ğŸŒ² RF |
| **Recall (no)** | **0.72** | 0.66 | ğŸŒ³ DT |
| **Interpretabilidad** | â­â­â­â­â­ | â­â­ | ğŸŒ³ DT |
| **Estabilidad** | â­â­â­ | â­â­â­â­â­ | ğŸŒ² RF |

### Importancia de Variables (Top 3 â€” ambos modelos)

```
ğŸ¥‡ CGPA          â†’  Factor dominante. CorrelaciÃ³n 0.88 con Chance of Admit.
ğŸ¥ˆ GRE Score     â†’  Criterio secundario. Especialmente en rangos intermedios de CGPA.
ğŸ¥‰ TOEFL Score   â†’  Tercer factor. Mayor relevancia en Random Forest.
```

### InterpretaciÃ³n PrÃ¡ctica Clave

> **Si CGPA â‰¤ 7.91 â†’ el modelo predice NO admisiÃ³n, independientemente de cualquier otra variable.**

Esto significa que el rendimiento acadÃ©mico acumulado es la barrera mÃ­nima para ser considerado candidato fuerte. Un GRE alto o una excelente carta de recomendaciÃ³n no compensan un CGPA bajo en este modelo.

---

## ğŸ–¼ï¸ GrÃ¡ficos Generados

| GrÃ¡fico | DescripciÃ³n |
|---|---|
| `01_analisis_exploratorio.png` | DistribuciÃ³n de `Chance of Admit`, conteo de clases, scatter CGPA y GRE vs probabilidad |
| `02_correlacion.png` | Heatmap de correlaciÃ³n de Pearson entre todas las variables |
| `03_arbol_decision.png` | Ãrbol de decisiÃ³n entrenado con `max_depth=4`, nodos coloreados por clase |
| `04_importancia_dt.png` | Importancia de variables por reducciÃ³n de Gini â€” Decision Tree |
| `05_importancia_rf.png` | Importancia de variables por MDI (Mean Decrease Impurity) â€” Random Forest |
| `06_matrices_confusion.png` | Matrices de confusiÃ³n comparadas lado a lado |
| `07_curva_roc.png` | Curva ROC con AUC para ambos modelos vs clasificador aleatorio |

---

## âš™ï¸ InstalaciÃ³n y EjecuciÃ³n

### Requisitos

- Python 3.8+
- pip

### 1. Clonar el repositorio

```bash
git clone https://github.com/AlejoTechEngineer/Predictive-Modeling-of-Graduate-Admissions-using-Tree-Based-Algorithms.git
cd "Predictive-Modeling-of-Graduate-Admissions-using-Tree-Based-Algorithms"
```

### 2. Instalar dependencias

```bash
pip install pandas numpy matplotlib seaborn scikit-learn
```

### 3. Ejecutar el script

```bash
python admission_clasificacion.py
```

### 4. Output esperado

```
Columnas: ['Serial No.', 'GRE Score', 'TOEFL Score', ...]
Forma del dataset: (500, 9)
...
Ãrbol de DecisiÃ³n - Accuracy CV: 0.8960 Â± 0.0403
Random Forest     - Accuracy CV: 0.9080 Â± 0.0312
Â¡Script completado exitosamente! Revisa los archivos PNG generados.
```

Los 7 archivos PNG se generan automÃ¡ticamente en la misma carpeta.

---

## ğŸ¯ Conclusiones

1. **CGPA es el predictor dominante** en ambos modelos. Su correlaciÃ³n de 0.88 con `Chance of Admit` y su posiciÃ³n como nodo raÃ­z del Ã¡rbol lo confirman empÃ­ricamente.

2. **Random Forest supera al Ãrbol de DecisiÃ³n** en accuracy (91.33% vs 89.33%), AUC-ROC (0.905 vs 0.888) y estabilidad en validaciÃ³n cruzada (Â±0.031 vs Â±0.040).

3. **El desbalance de clases (81/19) impacta el recall** de la clase minoritaria. El Ã¡rbol individual mantiene mejor equilibrio entre clases (recall "no" = 0.72), mientras que Random Forest prioriza la clase mayoritaria (recall "no" = 0.66).

4. **Ambos modelos superan ampliamente el clasificador aleatorio** (AUC > 0.88 en ambos casos), demostrando alta capacidad discriminativa real.

5. **El Ã¡rbol ofrece ventaja en interpretabilidad**: sus reglas if-else son directamente accionables por una instituciÃ³n educativa para diseÃ±ar criterios de preselecciÃ³n.

---

## ğŸ› ï¸ TecnologÃ­as

<div align="center">

| LibrerÃ­a | VersiÃ³n | Uso |
|---|---|---|
| `pandas` | 3.0.1 | Carga, manipulaciÃ³n y anÃ¡lisis de datos |
| `numpy` | 2.4.2 | Operaciones numÃ©ricas vectorizadas |
| `matplotlib` | 3.10.8 | Visualizaciones y exportaciÃ³n de grÃ¡ficos |
| `seaborn` | 0.13.2 | Heatmaps y visualizaciones estadÃ­sticas |
| `scikit-learn` | 1.8.0 | Modelos, mÃ©tricas y validaciÃ³n cruzada |

</div>

---

## ğŸ‘¨â€ğŸ’» Autor

<div align="center">

**Alejandro De Mendoza**  
IngenierÃ­a InformÃ¡tica 
FundaciÃ³n Universitaria Internacional de La Rioja (UNIR)  
BogotÃ¡ D.C., Colombia â€” 2026

[![GitHub](https://img.shields.io/badge/GitHub-AlejoTechEngineer-181717?style=for-the-badge&logo=github)](https://github.com/AlejoTechEngineer)

*Laboratorio desarrollado para Aprendizaje AutomÃ¡tico y MinerÃ­a de Datos*  
*Profesor: Ing. Rogerio Orlando BeltrÃ¡n Castro*

</div>

---

<div align="center">

â­ **Si este proyecto te fue Ãºtil, dale una estrella al repo** â­

*Made with ğŸ§  + â˜• + Python*

</div>
